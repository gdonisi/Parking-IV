{
    "name": "root",
    "gauges": {
        "CarBehavior.Policy.Entropy.mean": {
            "value": 0.20970523357391357,
            "min": 0.20970523357391357,
            "max": 0.5400329232215881,
            "count": 7
        },
        "CarBehavior.Policy.Entropy.sum": {
            "value": 2108.37646484375,
            "min": 2108.37646484375,
            "max": 5371.70751953125,
            "count": 7
        },
        "CarBehavior.Environment.EpisodeLength.mean": {
            "value": 1190.6,
            "min": 18.19083969465649,
            "max": 1190.6,
            "count": 7
        },
        "CarBehavior.Environment.EpisodeLength.sum": {
            "value": 5953.0,
            "min": 5953.0,
            "max": 9630.0,
            "count": 7
        },
        "CarBehavior.Step.mean": {
            "value": 69991.0,
            "min": 9948.0,
            "max": 69991.0,
            "count": 7
        },
        "CarBehavior.Step.sum": {
            "value": 69991.0,
            "min": 9948.0,
            "max": 69991.0,
            "count": 7
        },
        "CarBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 2.1798360347747803,
            "min": 0.30605605244636536,
            "max": 2.1798360347747803,
            "count": 7
        },
        "CarBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 348.7737731933594,
            "min": 161.29153442382812,
            "max": 1027.217529296875,
            "count": 7
        },
        "CarBehavior.Environment.CumulativeReward.mean": {
            "value": 21.359998846054076,
            "min": 0.4568642415462443,
            "max": 21.359998846054076,
            "count": 7
        },
        "CarBehavior.Environment.CumulativeReward.sum": {
            "value": 106.79999423027039,
            "min": 106.79999423027039,
            "max": 1140.0,
            "count": 7
        },
        "CarBehavior.Policy.ExtrinsicReward.mean": {
            "value": 21.359998846054076,
            "min": 0.4568642415462443,
            "max": 21.359998846054076,
            "count": 7
        },
        "CarBehavior.Policy.ExtrinsicReward.sum": {
            "value": 106.79999423027039,
            "min": 106.79999423027039,
            "max": 1140.0,
            "count": 7
        },
        "CarBehavior.Losses.PolicyLoss.mean": {
            "value": 0.2430059899038627,
            "min": 0.23831548321706503,
            "max": 0.24794058684535694,
            "count": 7
        },
        "CarBehavior.Losses.PolicyLoss.sum": {
            "value": 18.954467212501292,
            "min": 18.954467212501292,
            "max": 21.88760635886859,
            "count": 7
        },
        "CarBehavior.Losses.ValueLoss.mean": {
            "value": 0.35338506971244915,
            "min": 0.35338506971244915,
            "max": 2.005536165877685,
            "count": 7
        },
        "CarBehavior.Losses.ValueLoss.sum": {
            "value": 27.564035437571036,
            "min": 27.564035437571036,
            "max": 160.44289327021482,
            "count": 7
        },
        "CarBehavior.Policy.LearningRate.mean": {
            "value": 0.0002610004129998666,
            "min": 0.0002610004129998666,
            "max": 0.0002970368312202814,
            "count": 7
        },
        "CarBehavior.Policy.LearningRate.sum": {
            "value": 0.0203580322139896,
            "min": 0.0203580322139896,
            "max": 0.025902587065804398,
            "count": 7
        },
        "CarBehavior.Policy.Epsilon.mean": {
            "value": 0.18700013333333335,
            "min": 0.18700013333333335,
            "max": 0.19901227674418606,
            "count": 7
        },
        "CarBehavior.Policy.Epsilon.sum": {
            "value": 14.586010400000001,
            "min": 14.586010400000001,
            "max": 17.563343999999997,
            "count": 7
        },
        "CarBehavior.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005000000000000001,
            "max": 0.0005000000000000001,
            "count": 7
        },
        "CarBehavior.Policy.Beta.sum": {
            "value": 0.03900000000000001,
            "min": 0.03900000000000001,
            "max": 0.04550000000000001,
            "count": 7
        },
        "CarBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 7
        },
        "CarBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 7
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1709815465",
        "python_version": "3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\ciro_\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn config\\moveToGoal.yaml --initialize-from=prova2 --run-id=prova3 --force",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1709816480"
    },
    "total": 1015.2457041000016,
    "count": 1,
    "self": 0.008688999922014773,
    "children": {
        "run_training.setup": {
            "total": 0.09599720011465251,
            "count": 1,
            "self": 0.09599720011465251
        },
        "TrainerController.start_learning": {
            "total": 1015.1410178999649,
            "count": 1,
            "self": 1.422409414430149,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.226685600006022,
                    "count": 1,
                    "self": 7.226685600006022
                },
                "TrainerController.advance": {
                    "total": 1006.325258585508,
                    "count": 79937,
                    "self": 1.2379296988947317,
                    "children": {
                        "env_step": {
                            "total": 637.0479627886089,
                            "count": 79937,
                            "self": 333.5196355972439,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 302.66437090176623,
                                    "count": 79937,
                                    "self": 3.388358070864342,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 299.2760128309019,
                                            "count": 78182,
                                            "self": 299.2760128309019
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.8639562895987183,
                                    "count": 79937,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1006.2106342293555,
                                            "count": 79937,
                                            "is_parallel": true,
                                            "self": 735.6410660423571,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00039300008211284876,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00020890007726848125,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0001841000048443675,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0001841000048443675
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 270.56917518691625,
                                                    "count": 79937,
                                                    "is_parallel": true,
                                                    "self": 5.6550723852124065,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.806787016685121,
                                                            "count": 79937,
                                                            "is_parallel": true,
                                                            "self": 4.806787016685121
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 240.4430596913444,
                                                            "count": 79937,
                                                            "is_parallel": true,
                                                            "self": 240.4430596913444
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 19.66425609367434,
                                                            "count": 79937,
                                                            "is_parallel": true,
                                                            "self": 11.023716766852885,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 8.640539326821454,
                                                                    "count": 319748,
                                                                    "is_parallel": true,
                                                                    "self": 8.640539326821454
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 368.0393660980044,
                            "count": 79937,
                            "self": 1.591977005940862,
                            "children": {
                                "process_trajectory": {
                                    "total": 12.15096569166053,
                                    "count": 79937,
                                    "self": 12.15096569166053
                                },
                                "_update_policy": {
                                    "total": 354.296423400403,
                                    "count": 663,
                                    "self": 11.87732289871201,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 342.419100501691,
                                            "count": 22337,
                                            "self": 342.419100501691
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.400010660290718e-06,
                    "count": 1,
                    "self": 1.400010660290718e-06
                },
                "TrainerController._save_models": {
                    "total": 0.16666290001012385,
                    "count": 1,
                    "self": 0.011421300005167723,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.15524160000495613,
                            "count": 1,
                            "self": 0.15524160000495613
                        }
                    }
                }
            }
        }
    }
}